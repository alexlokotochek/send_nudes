{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ec2-35-157-142-225.eu-central-1.compute.amazonaws.com\n",
    "from IPython.display import Image, display\n",
    "import PIL.Image\n",
    "from io import StringIO\n",
    "import IPython.display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PREDICTOR_PATH = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "FEATHER_AMOUNT = 31\n",
    "KERNEL_FACTOR = 1\n",
    "\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "JAW_POINTS = list(range(0, 17))\n",
    "\n",
    "# Points used to line up the images.\n",
    "ALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS +\n",
    "                               RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS)\n",
    "\n",
    "# Points from the second image to overlay on the first. The convex hull of each\n",
    "# element will be overlaid.\n",
    "OVERLAY_POINTS = [\n",
    "    LEFT_EYE_POINTS,\n",
    "    RIGHT_EYE_POINTS, \n",
    "     #LEFT_BROW_POINTS,\n",
    "     #RIGHT_BROW_POINTS,\n",
    "    NOSE_POINTS, \n",
    "    MOUTH_POINTS,\n",
    "    #[24, 19, 68] \n",
    "]\n",
    "\n",
    "# Amount of blur to use during colour correction, as a fraction of the\n",
    "# pupillary distance.\n",
    "COLOUR_CORRECT_BLUR_FRAC = 0.8\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "    if len(rects) > 1:\n",
    "        print('Too many faces')\n",
    "        return None\n",
    "    if len(rects) == 0:\n",
    "        print('No faces')\n",
    "        return None\n",
    "    return numpy.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "\n",
    "def draw_convex_hull(im, points, color):\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(im, points, color=color)\n",
    "\n",
    "    \n",
    "def get_face_mask(im, landmarks):\n",
    "    im = numpy.zeros(im.shape[:2], dtype=numpy.float64)\n",
    "    for i, group in enumerate(OVERLAY_POINTS):\n",
    "        this_landmarks = landmarks[group]\n",
    "        # this_landmarks = 2*this_landmarks + this_landmarks[:, ::-1]\n",
    "        draw_convex_hull(im,\n",
    "                         this_landmarks,\n",
    "                         color=1)\n",
    "    im = numpy.array([im, im, im]).transpose((1, 2, 0))\n",
    "    im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
    "    im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
    "    # im = cv2.fastNlMeansDenoisingColored(im,\n",
    "    #                                  None,\n",
    "    #                                  10,\n",
    "    #                                  10,\n",
    "    #                                  7,\n",
    "    #                                  21)\n",
    "\n",
    "    return im\n",
    "    \n",
    "    \n",
    "def transformation_from_points(points1, points2):\n",
    "    # sum ||s*R*p1,i + T - p2,i||^2 -> min\n",
    "    points1 = points1.astype(numpy.float64)\n",
    "    points2 = points2.astype(numpy.float64)\n",
    "    c1 = numpy.mean(points1, axis=0)\n",
    "    c2 = numpy.mean(points2, axis=0)\n",
    "    points1 -= c1\n",
    "    points2 -= c2\n",
    "    s1 = numpy.std(points1)\n",
    "    s2 = numpy.std(points2)\n",
    "    points1 /= s1\n",
    "    points2 /= s2\n",
    "    U, S, Vt = numpy.linalg.svd(points1.T * points2)\n",
    "    R = (U * Vt).T\n",
    "    return numpy.vstack([numpy.hstack(((s2 / s1) * R,\n",
    "                                       c2.T - (s2 / s1) * R * c1.T)),\n",
    "                         numpy.matrix([0., 0., 1.])])\n",
    "\n",
    "\n",
    "def resize_im(im, new_h):\n",
    "    h, w, _ = im.shape\n",
    "    koeff_ratio = h*1./w\n",
    "    new_h = 512\n",
    "    new_w = new_h / koeff_ratio\n",
    "    antialias_koeff = new_h*1./h\n",
    "    im = cv2.resize(im, (int(new_w),int(new_h)), \n",
    "                    fx=antialias_koeff, \n",
    "                    fy=antialias_koeff, \n",
    "                    interpolation = cv2.INTER_AREA)\n",
    "    return im\n",
    "    \n",
    "def read_im_and_landmarks(fname):\n",
    "    \n",
    "    im = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "#     im = resize_im(im, 512)\n",
    "    s = get_landmarks(im)\n",
    "    return im, s\n",
    "\n",
    "\n",
    "def warp_im(im, M, dshape):\n",
    "    output_im = numpy.zeros(dshape, dtype=im.dtype)\n",
    "    cv2.warpAffine(im,\n",
    "                   M[:2],\n",
    "                   (dshape[1], dshape[0]),\n",
    "                   dst=output_im,\n",
    "                   borderMode=cv2.BORDER_TRANSPARENT,\n",
    "                   flags=cv2.WARP_INVERSE_MAP)\n",
    "    return output_im\n",
    "\n",
    "\n",
    "def correct_colours(im1, im2, landmarks1):\n",
    "    blur_amount = COLOUR_CORRECT_BLUR_FRAC * numpy.linalg.norm(\n",
    "                              numpy.mean(landmarks1[LEFT_EYE_POINTS], axis=0) -\n",
    "                              numpy.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
    "    blur_amount = int(blur_amount)\n",
    "    if blur_amount % 2 == 0:\n",
    "        blur_amount += 1\n",
    "    im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0)\n",
    "    im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0)\n",
    "    # /0 errors.\n",
    "    im2_blur += (128 * (im2_blur <= 1.0)).astype(im2_blur.dtype)\n",
    "    return (im2.astype(numpy.float64) * im1_blur.astype(numpy.float64) /\n",
    "                                                im2_blur.astype(numpy.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_forehead_point(landmarks):\n",
    "    corner_points = [24, 19, 27] # 27 is upper nose point\n",
    "    corner_points = -landmarks[:,0][corner_points], -landmarks[:,1][corner_points]\n",
    "    pt0 = np.array([int(corner_points[0][0]), int(corner_points[1][0])])\n",
    "    pt1 = np.array([int(corner_points[0][1]), int(corner_points[1][1])])\n",
    "    pt = np.array([int(corner_points[0][2]), int(corner_points[1][2])])\n",
    "    line_pt = pt1\n",
    "    line_vec = pt1 - pt0\n",
    "    pt_proj = np.dot(pt - line_pt, line_vec) * line_vec / np.dot(line_vec, line_vec)\n",
    "    pt_norm = pt - line_pt - pt_proj\n",
    "    pt_sym = pt - 2*pt_norm\n",
    "    mid = (pt0 + pt1)/2.\n",
    "    pt_sym += (-pt + mid)*0.2\n",
    "    return np.vstack([landmarks ,[-pt_sym[0], -pt_sym[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im1, landmarks1 = read_im_and_landmarks('./porn2.jpg')\n",
    "\n",
    "kernel = np.ones((KERNEL_FACTOR, KERNEL_FACTOR),np.float32)/(KERNEL_FACTOR**2)\n",
    "im1 = cv2.filter2D(im1, -1, kernel)\n",
    "    \n",
    "im2, landmarks2 = read_im_and_landmarks('./pidr.jpg')\n",
    "\n",
    "landmarks1 = add_forehead_point(landmarks1).astype(int)\n",
    "landmarks2 = add_forehead_point(landmarks2).astype(int)\n",
    "\n",
    "\n",
    "M = transformation_from_points(landmarks1[ALIGN_POINTS],\n",
    "                               landmarks2[ALIGN_POINTS])\n",
    "\n",
    "mask = get_face_mask(im2, landmarks2)\n",
    "warped_mask = warp_im(mask, M, im1.shape)\n",
    "combined_mask = numpy.max([get_face_mask(im1, landmarks1), warped_mask],\n",
    "                          axis=0)\n",
    "\n",
    "warped_im2 = warp_im(im2, M, im1.shape)\n",
    "warped_corrected_im2 = correct_colours(im1, warped_im2, landmarks1)\n",
    "\n",
    "output_im = im1 * (1.0 - combined_mask) + warped_corrected_im2 * combined_mask\n",
    "output_im = resize_im(output_im, 256)\n",
    "\n",
    "cv2.imwrite('output.jpg', output_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[[26,17, 27]]: left brow, right brow, upper nose (between eyes)\n",
    "\n",
    "corner_points = [24, 19, 68]\n",
    "corner_points = -landmarks1[:,0][corner_points], -landmarks1[:,1][corner_points]\n",
    "\n",
    "# OVERLAY_POINTS = [\n",
    "#     LEFT_EYE_POINTS + RIGHT_EYE_POINTS + #(LEFT_BROW_POINTS+[68]) \n",
    "#     #+ (RIGHT_BROW_POINTS+[68]),\n",
    "#     (NOSE_POINTS) + MOUTH_POINTS + \n",
    "#     [24, 19, 68]\n",
    "# ]\n",
    "\n",
    "\n",
    "plt.scatter(-landmarks1[:,0], -landmarks1[:,1], alpha=0.5)\n",
    "plt.scatter(corner_points[0], corner_points[1], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.scatter(-np.where(mask>0.)[1], -np.where(mask>0.)[0])\n",
    "# plt.show()\n",
    "\n",
    "im = numpy.zeros(im1.shape[:2], dtype=numpy.float64)\n",
    "\n",
    "for group in OVERLAY_POINTS:\n",
    "\n",
    "    points = landmarks1[group]\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(im, points, color=1)\n",
    "    \n",
    "group = [[24, 19, 68]]\n",
    "\n",
    "points = landmarks1[group]\n",
    "points = cv2.convexHull(points)\n",
    "cv2.fillConvexPoly(im, points, color=2)\n",
    "    \n",
    "    \n",
    "im = numpy.array([im, im, im]).transpose((1, 2, 0))\n",
    "im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
    "im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
    "\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(annotate_landmarks(im1, landmarks1))\n",
    "plt.imshow(warped_mask, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display(Image(filename='ava.jpg', width=200, height=100), )\n",
    "# display(Image(filename='porn.jpg', width=200, height=100), )\n",
    "# display(Image(filename='output.jpg', width=200, height=100), ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(output_im)\n",
    "# plt.imshow(warped_mask, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
