{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from asdad.porn_creator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    # include forehead triangle transplantation\n",
    "    # caution about fucking hairstyles\n",
    "    'USE_FOREHEAD': False,\n",
    "    # include brows transplantation\n",
    "    'USE_BROWS': False,\n",
    "    # if 0, output shakalization processis not applied\n",
    "    # otherwise it's result img height\n",
    "    # width will be adjusted proportionally\n",
    "    'SHAKALIZE_HEIGHT': 0,\n",
    "    # feather on the places where we cut off the eblo\n",
    "    # must be odd\n",
    "    'FEATHER_AMOUNT': 9,\n",
    "    # thing like colour transparency \n",
    "    # 1.0 to turn off transparency and colour adjustment\n",
    "    # 0..1\n",
    "    'COLOUR_CORRECT_BLUR_FRAC': 0.6,\n",
    "    # input face image will be less sharp\n",
    "    # 1 to turn off\n",
    "    # better to be int square\n",
    "    'EBLO_KERNEL_FACTOR': 6,\n",
    "    # the same thing bout body\n",
    "    # better to be int square\n",
    "    'TELKA_KERNEL_FACTOR': 2\n",
    "}\n",
    "\n",
    "im1 = cv2.imread('./asdad/pidr.jpg', cv2.IMREAD_COLOR)\n",
    "im2 = cv2.imread('./asdad/porn.jpg', cv2.IMREAD_COLOR)\n",
    "res, status = get_porn(im2, im1, params)\n",
    "print status\n",
    "cv2.imwrite('./asdad/res.jpg', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im1, landmarks1 = read_im_and_landmarks('./porn2.jpg')\n",
    "\n",
    "kernel = np.ones((KERNEL_FACTOR, KERNEL_FACTOR),np.float32)/(KERNEL_FACTOR**2)\n",
    "im1 = cv2.filter2D(im1, -1, kernel)\n",
    "    \n",
    "im2, landmarks2 = read_im_and_landmarks('./pidr.jpg')\n",
    "\n",
    "landmarks1 = add_forehead_point(landmarks1).astype(int)\n",
    "landmarks2 = add_forehead_point(landmarks2).astype(int)\n",
    "\n",
    "\n",
    "M = transformation_from_points(landmarks1[ALIGN_POINTS],\n",
    "                               landmarks2[ALIGN_POINTS])\n",
    "\n",
    "mask = get_face_mask(im2, landmarks2)\n",
    "warped_mask = warp_im(mask, M, im1.shape)\n",
    "combined_mask = numpy.max([get_face_mask(im1, landmarks1), warped_mask],\n",
    "                          axis=0)\n",
    "\n",
    "warped_im2 = warp_im(im2, M, im1.shape)\n",
    "warped_corrected_im2 = correct_colours(im1, warped_im2, landmarks1)\n",
    "\n",
    "output_im = im1 * (1.0 - combined_mask) + warped_corrected_im2 * combined_mask\n",
    "output_im = resize_im(output_im, 256)\n",
    "\n",
    "cv2.imwrite('output.jpg', output_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[[26,17, 27]]: left brow, right brow, upper nose (between eyes)\n",
    "\n",
    "corner_points = [24, 19, 68]\n",
    "corner_points = -landmarks1[:,0][corner_points], -landmarks1[:,1][corner_points]\n",
    "\n",
    "# OVERLAY_POINTS = [\n",
    "#     LEFT_EYE_POINTS + RIGHT_EYE_POINTS + #(LEFT_BROW_POINTS+[68]) \n",
    "#     #+ (RIGHT_BROW_POINTS+[68]),\n",
    "#     (NOSE_POINTS) + MOUTH_POINTS + \n",
    "#     [24, 19, 68]\n",
    "# ]\n",
    "\n",
    "\n",
    "plt.scatter(-landmarks1[:,0], -landmarks1[:,1], alpha=0.5)\n",
    "plt.scatter(corner_points[0], corner_points[1], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.scatter(-np.where(mask>0.)[1], -np.where(mask>0.)[0])\n",
    "# plt.show()\n",
    "\n",
    "im = numpy.zeros(im1.shape[:2], dtype=numpy.float64)\n",
    "\n",
    "for group in OVERLAY_POINTS:\n",
    "\n",
    "    points = landmarks1[group]\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(im, points, color=1)\n",
    "    \n",
    "group = [[24, 19, 68]]\n",
    "\n",
    "points = landmarks1[group]\n",
    "points = cv2.convexHull(points)\n",
    "cv2.fillConvexPoly(im, points, color=2)\n",
    "    \n",
    "    \n",
    "im = numpy.array([im, im, im]).transpose((1, 2, 0))\n",
    "im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
    "im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
    "\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(annotate_landmarks(im1, landmarks1))\n",
    "plt.imshow(warped_mask, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display(Image(filename='ava.jpg', width=200, height=100), )\n",
    "# display(Image(filename='porn.jpg', width=200, height=100), )\n",
    "# display(Image(filename='output.jpg', width=200, height=100), ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(output_im)\n",
    "# plt.imshow(warped_mask, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
